#!/usr/bin/env python3

# The data is produced by running the following commands:
# parameters:
# <input.mlir>: the input MLIR file generated by the compiler
# <block_size>: the cache block size in bytes, e.g., 8
# <associativity>: the cache associativity, e.g., 4
# <cache_size>: the cache size in bytes, e.g., 512
# predict the fully associative cache miss ratio
# cargo run -p analyzer --release -- -i <input.mlir> -o full.json barvinok --infinite-repeat --barvinok-arg=--approximation-method=scale --block-size=<block_size>
# calculate the associative cache miss ratio by Smith's method
# cargo run -p assoc-conv --release -- -i full.json -a <associativity> -o assoc.json
# The simulation data is generated by running the following commands:
# cache size needs to be transformed into bytes: b' = block_size * 8, c' = cache_size * b'
# run the simulator to get the miss ratios for different cache sizes
# cargo run -p cachegrind-runner --release -- -i ./analyzer/misc/polybench/const/const_syr2k.mlir -C <c'> -B<b'> -c32768 -b64 -a16 --database full.db --batched
# cargo run -p cachegrind-runner --release -- -i ./analyzer/misc/polybench/const/const_syr2k.mlir -C <c'> -B<b'> -A <associativity> -c32768 -b64 -a4 --database assoc.db --batched
# then in the plot, remember we have a times 64 for cache size? that is exactly c' = cache_size * b'.
# Can you change the code so that it automatically runs the above commands with the argparse inputs? Make sure intermediate files are saved to tempdir.
# Before, we use bytes. However, in the updated version, let's use number of blocks.

import sqlite3
import json
import matplotlib.pyplot as plt
import numpy as np
import argparse
import subprocess
import tempfile
import os
import sys
import time
import base64
import hashlib
import threading

# ANSI color codes
class Colors:
    RED = '\033[91m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    MAGENTA = '\033[95m'
    CYAN = '\033[96m'
    WHITE = '\033[97m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'
    RESET = '\033[0m'

class Spinner:
    """A simple rotating spinner for showing process activity"""
    def __init__(self, message="Processing"):
        self.spinner_chars = ['‚†ã', '‚†ô', '‚†π', '‚†∏', '‚†º', '‚†¥', '‚†¶', '‚†ß', '‚†á', '‚†è']
        self.message = message
        self.spinning = False
        self.thread = None
    
    def spin(self):
        """The spinning animation loop"""
        i = 0
        while self.spinning:
            char = self.spinner_chars[i % len(self.spinner_chars)]
            print(f"\r{Colors.BLUE}{char} {self.message}...{Colors.RESET}", end='', flush=True)
            time.sleep(0.1)
            i += 1
    
    def start(self):
        """Start the spinner in a separate thread"""
        self.spinning = True
        self.thread = threading.Thread(target=self.spin)
        self.thread.daemon = True
        self.thread.start()
    
    def stop(self):
        """Stop the spinner and clear the line"""
        self.spinning = False
        if self.thread:
            self.thread.join()
        print(f"\r{' ' * (len(self.message) + 10)}\r", end='', flush=True)

def run_command(cmd, description, step_num=None, total_steps=None):
    """Run a command and handle errors with colorized output"""
    if step_num and total_steps:
        print(f"\n{Colors.BOLD}{Colors.BLUE}üìã Step {step_num}/{total_steps}: {description}{Colors.RESET}")
    else:
        print(f"\n{Colors.BOLD}{Colors.BLUE}üîÑ {description}{Colors.RESET}")
    
    print(f"{Colors.CYAN}Command: {' '.join(cmd)}{Colors.RESET}")
    
    # Create and start spinner
    spinner = Spinner("Running")
    spinner.start()
    
    try:
        # Start the process
        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        
        # Wait for process to complete
        stdout, stderr = process.communicate()
        
        # Stop spinner
        spinner.stop()
        
        if process.returncode == 0:
            print(f"{Colors.GREEN}{Colors.BOLD}‚úÖ {description} completed successfully!{Colors.RESET}")
            return subprocess.CompletedProcess(cmd, 0, stdout, stderr)
        else:
            raise subprocess.CalledProcessError(process.returncode, cmd, stdout, stderr)
            
    except subprocess.CalledProcessError as e:
        spinner.stop()
        print(f"\n{Colors.RED}{Colors.BOLD}‚ùå Error running {description}{Colors.RESET}")
        print(f"{Colors.RED}Return code: {e.returncode}{Colors.RESET}")
        if e.stdout:
            print(f"{Colors.YELLOW}stdout: {e.stdout}{Colors.RESET}")
        if e.stderr:
            print(f"{Colors.RED}stderr: {e.stderr}{Colors.RESET}")
        sys.exit(1)
    except KeyboardInterrupt:
        spinner.stop()
        print(f"\n{Colors.YELLOW}{Colors.BOLD}‚ö†Ô∏è  Process interrupted by user{Colors.RESET}")
        sys.exit(1)

def extract_simulation_data(db_path, block_size_bytes):
    """Extract miss ratios from simulation database"""
    print(f"{Colors.CYAN}üìä Extracting simulation data from {os.path.basename(db_path)}...{Colors.RESET}")
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # Get all records and compute miss ratios
    cursor.execute("SELECT d1_cache_size, d1_miss_count, total_access FROM records ORDER BY d1_cache_size")
    results = cursor.fetchall()
    
    cache_sizes = []
    miss_ratios = []
    
    for cache_size, miss_count, total_access in results:
        if total_access > 0:  # Avoid division by zero
            miss_ratio = miss_count / total_access
            # Convert cache size from bytes to number of blocks
            cache_sizes.append(cache_size // block_size_bytes)
            miss_ratios.append(miss_ratio)
    
    conn.close()
    return cache_sizes, miss_ratios

def extract_prediction_data(json_path):
    """Extract miss ratios from prediction JSON file"""
    print(f"{Colors.CYAN}üìà Extracting prediction data from {os.path.basename(json_path)}...{Colors.RESET}")
    with open(json_path, 'r') as f:
        data = json.load(f)
    
    miss_ratio_curve = data.get("miss_ratio_curve", {})
    
    # Get turning points (already in number of blocks)
    turning_points = miss_ratio_curve.get("turning_points", [])
    miss_ratios = miss_ratio_curve.get("miss_ratio", [])
    
    # If no turning points, generate based on miss_ratios length
    if not turning_points and miss_ratios:
        turning_points = [2**i for i in range(len(miss_ratios))]
    
    return turning_points, miss_ratios

def main():
    """Generate cache miss ratio analysis with automatic command execution"""
    # Print colorful header
    print(f"\n{Colors.BOLD}{Colors.MAGENTA}" + "="*60 + f"{Colors.RESET}")
    print(f"{Colors.BOLD}{Colors.MAGENTA}üöÄ CACHE MISS RATIO ANALYSIS TOOL üöÄ{Colors.RESET}")
    print(f"{Colors.BOLD}{Colors.MAGENTA}" + "="*60 + f"{Colors.RESET}\n")
    
    parser = argparse.ArgumentParser(description='Cache miss ratio analysis tool')
    parser.add_argument('-i', '--input', required=True, help='Input MLIR file')
    parser.add_argument('-b', '--block-size', type=int, default=8, help='Cache block size in number of elements (default: 8)')
    parser.add_argument('-e', '--element-size', type=int, default=8, help='Element size in bytes (default: 8)')
    parser.add_argument('-a', '--associativity', type=int, default=4, help='Cache associativity (default: 4)')
    parser.add_argument('-c', '--cache-size', type=int, default=512, help='Cache size in bytes (default: 512)')
    parser.add_argument('-d', '--data-dir', default='/tmp', help='Directory for intermediate files (default: /tmp)')
    
    args = parser.parse_args()
    
    # Calculate block size in bytes
    block_size_bytes = args.block_size * args.element_size
    
    # Generate file prefix based on input file and arguments
    # Create a hash of the arguments to keep filename manageable
    arg_string = f"{args.input}_{args.block_size}_{args.element_size}_{args.associativity}_{args.cache_size}"
    arg_hash = hashlib.md5(arg_string.encode()).hexdigest()[:8]
    input_basename = os.path.basename(args.input).replace('.', '_')
    file_prefix = f"{input_basename}_{arg_hash}"
    
    # Print configuration with emojis and colors
    print(f"{Colors.BOLD}{Colors.YELLOW}üìã Configuration:{Colors.RESET}")
    print(f"  üéØ Input file: {Colors.CYAN}{args.input}{Colors.RESET}")
    print(f"  üìè Block size: {Colors.GREEN}{args.block_size} elements √ó {args.element_size} bytes = {block_size_bytes} bytes{Colors.RESET}")
    print(f"  üî¢ Associativity: {Colors.GREEN}{args.associativity}-way{Colors.RESET}")
    print(f"  üíæ Cache size: {Colors.GREEN}{args.cache_size} blocks{Colors.RESET}")
    print(f"  üìÅ Data directory: {Colors.CYAN}{args.data_dir}{Colors.RESET}")
    print(f"  üè∑Ô∏è  File prefix: {Colors.YELLOW}{file_prefix}{Colors.RESET}")
    
    # Ensure data directory exists
    os.makedirs(args.data_dir, exist_ok=True)
    print(f"\n{Colors.YELLOW}üìÅ Using data directory: {Colors.CYAN}{args.data_dir}{Colors.RESET}")
    
    # File paths with prefixed names to avoid conflicts
    full_json = os.path.join(args.data_dir, f"{file_prefix}_full.json")
    assoc_json = os.path.join(args.data_dir, f"{file_prefix}_assoc.json")
    full_db = os.path.join(args.data_dir, f"{file_prefix}_full.db")
    assoc_db = os.path.join(args.data_dir, f"{file_prefix}_assoc.db")
        
    # Step 1: Predict fully associative cache miss ratio
    if os.path.exists(full_json):
        print(f"\n{Colors.BOLD}{Colors.GREEN}‚è≠Ô∏è  Step 1/4: Skipping fully associative analysis - file exists: {os.path.basename(full_json)}{Colors.RESET}")
    else:
        cmd1 = [
            "cargo", "run", "-p", "analyzer", "--release", "--",
            "--json",
            "-i", args.input,
            "-o", full_json,
            "barvinok",
            "--infinite-repeat",
            "--barvinok-arg=--approximation-method=scale",
            f"--block-size={args.block_size}"
        ]
        run_command(cmd1, "üî¨ Analyzing fully associative cache", 1, 4)
        
    # Step 2: Calculate associative cache miss ratio by Smith's method
    if os.path.exists(assoc_json):
        print(f"\n{Colors.BOLD}{Colors.GREEN}‚è≠Ô∏è  Step 2/4: Skipping associative conversion - file exists: {os.path.basename(assoc_json)}{Colors.RESET}")
    else:
        cmd2 = [
            "cargo", "run", "-p", "assoc-conv", "--release", "--",
            "-i", full_json,
            "-a", str(args.associativity),
            "-o", assoc_json
        ]
        run_command(cmd2, f"üîÑ Converting to {args.associativity}-way associative cache", 2, 4)
        
    # Calculate cache parameters for simulation
    # b' = block_size_bytes, c' = cache_size * b'
    b_prime = block_size_bytes
    c_prime = args.cache_size * b_prime
    
    # Step 3: Run simulator for fully associative cache
    if os.path.exists(full_db):
        print(f"\n{Colors.BOLD}{Colors.GREEN}‚è≠Ô∏è  Step 3/4: Skipping fully associative simulation - file exists: {os.path.basename(full_db)}{Colors.RESET}")
    else:
        cmd3 = [
            "cargo", "run", "-p", "cachegrind-runner", "--release", "--",
            "-i", args.input,
            "-C", str(c_prime),
            f"-B{b_prime}",
            "-c32768",
            "-b64",
            "-a16",
            "--database", full_db,
            "--batched"
        ]
        run_command(cmd3, "üñ•Ô∏è Running simulation for fully associative cache", 3, 4)
    
    # Step 4: Run simulator for associative cache
    if os.path.exists(assoc_db):
        print(f"\n{Colors.BOLD}{Colors.GREEN}‚è≠Ô∏è  Step 4/4: Skipping associative simulation - file exists: {os.path.basename(assoc_db)}{Colors.RESET}")
    else:
        cmd4 = [
            "cargo", "run", "-p", "cachegrind-runner", "--release", "--",
            "-i", args.input,
            "-C", str(c_prime),
            f"-B{b_prime}",
            "-A", str(args.associativity),
            "-c32768",
            "-b64",
            "-a4",
            "--database", assoc_db,
            "--batched"
        ]
        run_command(cmd4, f"üñ•Ô∏è Running simulation for {args.associativity}-way associative cache", 4, 4)
        
    # Step 5: Generate plots
    print(f"\n{Colors.BOLD}{Colors.MAGENTA}üìä Generating plots...{Colors.RESET}")
    plt.figure(figsize=(12, 8))
    
    # Simulation data sources
    simulation = [
        (f"{args.associativity}-way", assoc_db),
        ("fully", full_db),
    ]
    
    # Prediction data sources
    prediction = [
        (f"{args.associativity}-way", assoc_json),
        ("fully", full_json),
    ]
        
    # Plot simulation data
    for name, db_file in simulation:
        try:
            cache_sizes, miss_ratios = extract_simulation_data(db_file, block_size_bytes)
            plt.plot(cache_sizes, miss_ratios, 'o-', label=f'Simulation - {name}', linewidth=2, markersize=6)
            print(f"{Colors.GREEN}‚úÖ Loaded simulation data for {name}: {len(cache_sizes)} points{Colors.RESET}")
        except Exception as e:
            print(f"{Colors.RED}‚ùå Error loading simulation data from {db_file}: {e}{Colors.RESET}")
    
    # Plot prediction data
    for name, json_file in prediction:
        try:
            cache_sizes, miss_ratios = extract_prediction_data(json_file)
            plt.plot(cache_sizes, miss_ratios, 's--', label=f'Prediction - {name}', linewidth=2, markersize=4)
            print(f"{Colors.GREEN}‚úÖ Loaded prediction data for {name}: {len(cache_sizes)} points{Colors.RESET}")
        except Exception as e:
            print(f"{Colors.RED}‚ùå Error loading prediction data from {json_file}: {e}{Colors.RESET}")
    
    # Set plot properties
    plt.xlabel('Cache Size (number of blocks)', fontsize=14)
    plt.ylabel('Miss Ratio', fontsize=14)
    plt.title('Cache Miss Ratio Comparison: Simulation vs Prediction', fontsize=16)
    plt.grid(True, alpha=0.3)
    plt.legend(fontsize=12)
    
    # Use log scale for x-axis
    plt.xscale('log')
    
    # Set y-axis limits
    plt.ylim(0, 1)
    
    plt.tight_layout()
    
    # Save the plot
    plt.savefig('cache_miss_ratio_comparison.png', dpi=300, bbox_inches='tight')
    plt.savefig('cache_miss_ratio_comparison.svg', bbox_inches='tight')
    
    print(f"\n{Colors.GREEN}{Colors.BOLD}üéâ SUCCESS! Plot saved as:{Colors.RESET}")
    print(f"  üìä {Colors.CYAN}cache_miss_ratio_comparison.png{Colors.RESET}")
    print(f"  üìä {Colors.CYAN}cache_miss_ratio_comparison.svg{Colors.RESET}")
    
    print(f"\n{Colors.BOLD}{Colors.MAGENTA}üéä Analysis completed successfully! üéä{Colors.RESET}")
    print(f"{Colors.BOLD}{Colors.MAGENTA}" + "="*60 + f"{Colors.RESET}\n")
    
    # Show the plot
    plt.show()

if __name__ == "__main__":
    main()